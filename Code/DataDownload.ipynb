{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ef976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 1. Definição dos date_ranges ────────────────────────────\n",
    "# 1.1. Intervalo mensal: de janeiro/2017 a dezembro/2024 (formato \"YYYYMM\")\n",
    "date_range_monthly = (\n",
    "    pd.date_range(start='2024-01-01', end='2024-12-31', freq='M')\n",
    "      .strftime(\"%Y%m\")\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "# 1.2. Intervalo trimestral: de março/2017 a dezembro/2024 (formato \"YYYYMM\")\n",
    "date_range_quarterly = (\n",
    "    pd.date_range(start='2024-01-01', end='2024-12-31', freq='Q')\n",
    "      .strftime(\"%Y%m\")\n",
    "      .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2. Definição e criação de diretórios principais ───────────────────────────\n",
    "base_dir    = Path('..')                \n",
    "dir_inputs  = base_dir / 'Input'        \n",
    "dir_outputs = base_dir / 'Output'       \n",
    "\n",
    "for d in (dir_inputs, dir_outputs):\n",
    "    d.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4518172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 3. Pipeline COSIF Individual ──────────────────────────────────────────────\n",
    "\n",
    "# 3.1. Diretório para baixar/armazenar COSIF Individual\n",
    "cosif_ind_dir = dir_inputs / 'COSIF' / 'individual'\n",
    "cosif_ind_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3.2. Download e extração dos arquivos mensais (raw, sem filtros)\n",
    "for date in date_range_monthly:\n",
    "    subfolder = cosif_ind_dir / date\n",
    "    subfolder.mkdir(exist_ok=True)\n",
    "\n",
    "    if any(subfolder.glob('*.csv')):\n",
    "        continue\n",
    "\n",
    "    downloaded = False\n",
    "    used_suffix = None\n",
    "\n",
    "    for suffix in ('BANCOS.csv', 'BANCOS.zip', 'BANCOS.csv.zip'):\n",
    "        url = f\"https://www.bcb.gov.br/content/estabilidadefinanceira/cosif/Bancos/{date}{suffix}\"\n",
    "        local_file = cosif_ind_dir / f\"{date}{suffix}\"\n",
    "\n",
    "        if local_file.exists():\n",
    "            downloaded = True\n",
    "            used_suffix = suffix\n",
    "            break\n",
    "\n",
    "        resp = requests.get(url, timeout=30)\n",
    "        content_type = resp.headers.get('Content-Type', '').lower()\n",
    "        is_html_error = (\n",
    "            resp.status_code != 200\n",
    "            or b'<!DOCTYPE html' in resp.content[:20]\n",
    "            or 'text/html' in content_type\n",
    "        )\n",
    "\n",
    "        if not is_html_error:\n",
    "            with open(local_file, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "            downloaded = True\n",
    "            used_suffix = suffix\n",
    "            break\n",
    "\n",
    "    if downloaded and used_suffix:\n",
    "        if used_suffix.endswith('.zip'):\n",
    "            zip_path = cosif_ind_dir / f\"{date}{used_suffix}\"\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(subfolder)\n",
    "        else:\n",
    "            csv_path = cosif_ind_dir / f\"{date}{used_suffix}\"\n",
    "            destino = subfolder / csv_path.name\n",
    "            if not destino.exists():\n",
    "                csv_path.rename(destino)\n",
    "\n",
    "# 3.3. Carregar TODOS os CSVs individuais em um DataFrame único (raw)\n",
    "df_list = []\n",
    "for date in date_range_monthly:\n",
    "    subfolder = cosif_ind_dir / date\n",
    "    if not subfolder.exists():\n",
    "        continue\n",
    "\n",
    "    csv_paths = list(subfolder.glob(f\"{date}BANCOS*.csv\"))\n",
    "    for csv_path in csv_paths:\n",
    "        temp_df = pd.read_csv(\n",
    "            csv_path,\n",
    "            header=3,\n",
    "            encoding='unicode_escape',\n",
    "            on_bad_lines='skip',\n",
    "            sep=';',\n",
    "            decimal=','\n",
    "        )\n",
    "        df_list.append(temp_df)\n",
    "\n",
    "df_cosif_individual_full = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 3.4. Exportar raw Individual para Parquet\n",
    "df_cosif_individual_full.to_parquet(\n",
    "    dir_outputs / 'df_cosif_individual_full.parquet',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# 3.5. (Opcional) Dicionário de contas Individual em Excel\n",
    "account_name = (\n",
    "    df_cosif_individual_full\n",
    "    .sort_values('CONTA')\n",
    "    .drop_duplicates(subset=['CONTA'], keep='last')\n",
    "    [['CONTA', 'NOME_CONTA']]\n",
    ")\n",
    "def remove_illegal(text: str) -> str:\n",
    "    return re.sub(r'[\\x00-\\x1F\\x7F]', '', text)\n",
    "\n",
    "account_name['NOME_CONTA'] = account_name['NOME_CONTA'].astype(str).apply(remove_illegal)\n",
    "account_name.to_excel(dir_outputs / 'cosif_account_name.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4. Pipeline COSIF Prudencial ──────────────────────────────────────────────\n",
    "\n",
    "# 4.1. Diretório para baixar/armazenar COSIF Prudencial\n",
    "cosif_prud_dir = dir_inputs / 'COSIF' / 'prudencial'\n",
    "cosif_prud_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4.2. Download e extração dos arquivos mensais (raw, sem filtros)\n",
    "for date in date_range_monthly:\n",
    "    subfolder = cosif_prud_dir / date\n",
    "    subfolder.mkdir(exist_ok=True)\n",
    "\n",
    "    if any(subfolder.glob('*.csv')):\n",
    "        continue\n",
    "\n",
    "    downloaded = False\n",
    "    used_suffix = None\n",
    "\n",
    "    for suffix in ('BLOPRUDENCIAL.csv', 'BLOPRUDENCIAL.zip', 'BLOPRUDENCIAL.csv.zip'):\n",
    "        url = f\"https://www.bcb.gov.br/content/estabilidadefinanceira/cosif/Conglomerados-prudenciais/{date}{suffix}\"\n",
    "        local_file = cosif_prud_dir / f\"{date}{suffix}\"\n",
    "\n",
    "        if local_file.exists():\n",
    "            downloaded = True\n",
    "            used_suffix = suffix\n",
    "            break\n",
    "\n",
    "        resp = requests.get(url, timeout=30)\n",
    "        content_type = resp.headers.get('Content-Type', '').lower()\n",
    "        is_html_error = (\n",
    "            resp.status_code != 200\n",
    "            or b'<!DOCTYPE html' in resp.content[:20]\n",
    "            or 'text/html' in content_type\n",
    "        )\n",
    "\n",
    "        if not is_html_error:\n",
    "            with open(local_file, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "            downloaded = True\n",
    "            used_suffix = suffix\n",
    "            break\n",
    "\n",
    "    if downloaded and used_suffix:\n",
    "        if used_suffix.endswith('.zip'):\n",
    "            zip_path = cosif_prud_dir / f\"{date}{used_suffix}\"\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(subfolder)\n",
    "        else:\n",
    "            csv_path = cosif_prud_dir / f\"{date}{used_suffix}\"\n",
    "            destino = subfolder / csv_path.name\n",
    "            if not destino.exists():\n",
    "                csv_path.rename(destino)\n",
    "\n",
    "# 4.3. Carregar TODOS os CSVs Prudencial em um DataFrame único (raw)\n",
    "df_prud_list = []\n",
    "for date in date_range_monthly:\n",
    "    subfolder = cosif_prud_dir / date\n",
    "    if not subfolder.exists():\n",
    "        continue\n",
    "\n",
    "    csv_paths = list(subfolder.glob(f\"{date}BLOPRUDENCIAL*.csv\"))\n",
    "    for csv_path in csv_paths:\n",
    "        temp_df = pd.read_csv(\n",
    "            csv_path,\n",
    "            header=3,\n",
    "            encoding='unicode_escape',\n",
    "            on_bad_lines='skip',\n",
    "            sep=';',\n",
    "            decimal=','\n",
    "        )\n",
    "        df_prud_list.append(temp_df)\n",
    "\n",
    "df_cosif_prudencial_full = pd.concat(df_prud_list, ignore_index=True)\n",
    "\n",
    "# 4.4. Exportar raw Prudencial para Parquet\n",
    "df_cosif_prudencial_full.to_parquet(\n",
    "    dir_outputs / 'df_cosif_prudencial_full.parquet',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# 4.5. (Opcional) Dicionário de contas Prudencial em Excel\n",
    "account_prud = (\n",
    "    df_cosif_prudencial_full\n",
    "    .sort_values('CONTA')\n",
    "    .drop_duplicates(subset=['CONTA'], keep='last')\n",
    "    [['CONTA', 'NOME_CONTA']]\n",
    ")\n",
    "account_prud['NOME_CONTA'] = account_prud['NOME_CONTA'].astype(str).apply(remove_illegal)\n",
    "account_prud.to_excel(dir_outputs / 'cosif_prudencial_account_name.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6623c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5. Pipeline IFDATA (valores + cadastro) – VERSÃO ATUALIZADA PARA TODOS TIPOS DE INSTITUIÇÃO ─────────────────────────────────\n",
    "# 5.1. Diretório para baixar/armazenar IFDATA de VALORES\n",
    "ifdata_dir = dir_inputs / 'IFDATA'\n",
    "ifdata_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 5.2. Download dos CSVs “IfDataValores” (métricas) PARA TODOS OS TIPOS DE INSTITUIÇÃO\n",
    "# Vamos iterar sobre cada trimestre e cada tipo de instituição (1 a 4), usando Relatorio='T' para trazer todos os relatórios\n",
    "tipos_instit = [1, 2, 3]  # TipoInstituicao disponíveis na API\n",
    "for date in date_range_quarterly:\n",
    "    for tipo in tipos_instit:\n",
    "        url_val = (\n",
    "            \"https://olinda.bcb.gov.br/olinda/servico/IFDATA/versao/v1/odata/\"\n",
    "            f\"IfDataValores(AnoMes=@AnoMes,TipoInstituicao=@TipoInstituicao,Relatorio=@Relatorio)?\"\n",
    "            f\"@AnoMes={date}&@TipoInstituicao={tipo}&@Relatorio='T'\"\n",
    "            \"&$format=text/csv\"\n",
    "        )\n",
    "        output_csv_val = ifdata_dir / f\"{date}_{tipo}.csv\"\n",
    "        if not output_csv_val.exists():\n",
    "            resp = requests.get(url_val, timeout=60)\n",
    "            with open(output_csv_val, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "\n",
    "# 5.3. Leitura de TODOS os CSVs “IfDataValores” em um DataFrame único\n",
    "df_if_list = []\n",
    "for date in date_range_quarterly:\n",
    "    for tipo in tipos_instit:\n",
    "        path = ifdata_dir / f\"{date}_{tipo}.csv\"\n",
    "        if path.exists() and path.stat().st_size > 0:\n",
    "            temp = pd.read_csv(\n",
    "                path,\n",
    "                encoding='unicode_escape',\n",
    "                on_bad_lines='skip',\n",
    "                sep=',',\n",
    "                decimal=','\n",
    "            )\n",
    "            # Garantir que a coluna TipoInstituicao reflita corretamente o tipo que baixamos\n",
    "            if 'TipoInstituicao' not in temp.columns:\n",
    "                temp['TipoInstituicao'] = tipo\n",
    "            df_if_list.append(temp)\n",
    "df_if_prudencial_full = pd.concat(df_if_list, ignore_index=True)\n",
    "\n",
    "\n",
    "# ─── 5.4. Pipeline IFDATA_CADASTRO ─────────────────────────────────────────────\n",
    "# 5.4.1. Cria diretório para baixar/armazenar “IfDataCadastro”\n",
    "ifdata_cadastro_dir = dir_inputs / 'IFDATA_Cadastro'\n",
    "ifdata_cadastro_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 5.4.2. Download dos CSVs “IfDataCadastro” da API\n",
    "for date in date_range_monthly:\n",
    "    url_cadastro = (\n",
    "        f\"https://olinda.bcb.gov.br/olinda/servico/IFDATA/versao/v1/odata/\"\n",
    "        f\"IfDataCadastro(AnoMes=@AnoMes)?@AnoMes={date}&$format=text/csv\"\n",
    "    )\n",
    "    output_csv_cad = ifdata_cadastro_dir / f\"IfDataCadastro_{date}.csv\"\n",
    "    if not output_csv_cad.exists():\n",
    "        resp = requests.get(url_cadastro, timeout=60)\n",
    "        with open(output_csv_cad, 'wb') as f:\n",
    "            f.write(resp.content)\n",
    "\n",
    "# 5.4.3. Leitura de TODOS os CSVs “IfDataCadastro” em um DataFrame único\n",
    "df_if_cad_list = []\n",
    "for date in date_range_monthly:\n",
    "    path = ifdata_cadastro_dir / f\"IfDataCadastro_{date}.csv\"\n",
    "    if path.exists() and path.stat().st_size > 0:\n",
    "        temp_cad = pd.read_csv(\n",
    "            path,\n",
    "            encoding='utf-8',\n",
    "            on_bad_lines='skip',\n",
    "            sep=',',\n",
    "            decimal='.'\n",
    "        )\n",
    "        df_if_cad_list.append(temp_cad)\n",
    "if df_if_cad_list:\n",
    "    df_if_cadastro_full = pd.concat(df_if_cad_list, ignore_index=True)\n",
    "else:\n",
    "    df_if_cadastro_full = pd.DataFrame()  # Se nenhum CSV existir, DataFrame vazio\n",
    "\n",
    "# 5.4.4. Ajustes iniciais em df_if_cadastro_full\n",
    "if not df_if_cadastro_full.empty:\n",
    "    df_if_cadastro_full = df_if_cadastro_full.rename(columns={\n",
    "        'Data': 'DATA',\n",
    "        'CodConglomeradoPrudencial': 'COD_CONGL'\n",
    "    })\n",
    "    df_if_cadastro_full['DATA'] = pd.to_numeric(df_if_cadastro_full['DATA'], errors='coerce').astype(int)\n",
    "    df_if_cadastro_full['COD_CONGL'] = df_if_cadastro_full['COD_CONGL'].astype(str)\n",
    "\n",
    "    # Remover caracteres não imprimíveis das colunas textuais de cadastro\n",
    "    def remove_illegal(text: str) -> str:\n",
    "        return re.sub(r'[\\x00-\\x1F\\x7F]', '', str(text))\n",
    "    for col in ['NomeInstituicao','SegmentoTb','Atividade','Uf','Municipio','Situacao']:\n",
    "        if col in df_if_cadastro_full.columns:\n",
    "            df_if_cadastro_full[col] = df_if_cadastro_full[col].astype(str).apply(remove_illegal)\n",
    "\n",
    "# ─── 5.5. Padronização de colunas em df_if_prudencial_full (valores) ─────────────\n",
    "def map_coluna(c):\n",
    "    return {\n",
    "        79647: \"Tier_1\",\n",
    "        79648: \"Tier_2\",\n",
    "        79649: \"Capital\",\n",
    "        79650: \"CRWA\",\n",
    "        79651: \"MRWA\",\n",
    "        79656: \"ORWA\",\n",
    "        79664: \"BIS\",\n",
    "        79665: \"RWA\"\n",
    "    }.get(c, f\"Conta_{c}\")\n",
    "\n",
    "df_if_prudencial_full['NomeColuna'] = df_if_prudencial_full['Conta'].apply(map_coluna)\n",
    "\n",
    "# 5.5.1. (Opcional) Dicionário de contas IFDATA em Excel\n",
    "account_name_ifdata = (\n",
    "    df_if_prudencial_full\n",
    "    .sort_values('Conta')\n",
    "    .drop_duplicates(subset=['Conta'], keep='last')\n",
    "    [['Conta', 'NomeColuna']]\n",
    ")\n",
    "account_name_ifdata['NomeColuna'] = account_name_ifdata['NomeColuna'].astype(str).apply(remove_illegal)\n",
    "account_name_ifdata.to_excel(dir_outputs / 'if_account_name.xlsx', index=False)\n",
    "\n",
    "# ─── 5.6. Ajuste final de nomes e tipos em df_if_prudencial_full (valores) ─────────\n",
    "df_if_prudencial_full = df_if_prudencial_full.rename(columns={\n",
    "    'CodInst': 'COD_CONGL',\n",
    "    'AnoMes': 'DATA'\n",
    "})\n",
    "df_if_prudencial_full['DATA'] = pd.to_numeric(df_if_prudencial_full['DATA'], errors='coerce').astype(int)\n",
    "df_if_prudencial_full['COD_CONGL'] = df_if_prudencial_full['COD_CONGL'].astype(str)\n",
    "\n",
    "# ─── 5.7. Merge de “IfDataValores” (df_if_prudencial_full) com “IfDataCadastro” ────\n",
    "if not df_if_cadastro_full.empty:\n",
    "    df_if_combined = pd.merge(\n",
    "        df_if_prudencial_full,\n",
    "        df_if_cadastro_full,\n",
    "        on=['DATA', 'COD_CONGL'],\n",
    "        how='left',\n",
    "        validate='many_to_many'   # antes era 'many_to_one'\n",
    "    )\n",
    "else:\n",
    "    df_if_combined = df_if_prudencial_full.copy()\n",
    "\n",
    "# 5.7.1. Verificar colunas resultantes\n",
    "print(\"Colunas após merge Valores + Cadastro (IFDATA):\")\n",
    "print(df_if_combined.columns.tolist())\n",
    "print(\"Shape df_if_combined:\", df_if_combined.shape)\n",
    "\n",
    "# ─── 5.8. Correção de encoding de texto em df_if_combined ─────────────────────────\n",
    "def corrigir_encoding(coluna):\n",
    "    return coluna.astype(str).str.encode('latin1', errors='ignore').str.decode('utf-8', errors='ignore')\n",
    "\n",
    "colunas_texto_if = ['NomeRelatorio','Grupo','NomeColuna','DescricaoColuna']\n",
    "for col in colunas_texto_if:\n",
    "    if col in df_if_combined.columns:\n",
    "        df_if_combined[col] = corrigir_encoding(df_if_combined[col])\n",
    "\n",
    "# ─── 5.9. Exportar DataFrame unificado de IFDATA para Parquet ────────────────────\n",
    "df_if_combined.to_parquet(\n",
    "    dir_outputs / 'df_if_prudencial_full.parquet',\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 6. Combinações finais (sem filtros) ───────────────────────────────────────\n",
    "\n",
    "# 6.1. Assegurar que 'DATA' exista em df_cosif_prudencial_full (a partir de '#DATA_BASE')\n",
    "if '#DATA_BASE' in df_cosif_prudencial_full.columns:\n",
    "    df_cosif_prudencial_full.rename(columns={'#DATA_BASE': 'DATA'}, inplace=True)\n",
    "df_cosif_prudencial_full['DATA'] = (\n",
    "    pd.to_datetime(df_cosif_prudencial_full['DATA'].astype(str), format='%Y%m')\n",
    "      .dt.strftime('%Y%m')\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "# Agora sim podemos mapear (raw, sem drop_duplicates)\n",
    "df_prud_mapping = df_cosif_prudencial_full[['DATA', 'CNPJ', 'COD_CONGL', 'NOME_CONGL']]\n",
    "\n",
    "\n",
    "# 6.2. Pivot opcional do Individual (wide)\n",
    "# Primeiro, cria 'DATA' a partir de '#DATA_BASE' em df_cosif_individual_full\n",
    "if '#DATA_BASE' in df_cosif_individual_full.columns:\n",
    "    df_cosif_individual_full.rename(columns={'#DATA_BASE': 'DATA'}, inplace=True)\n",
    "df_cosif_individual_full['DATA'] = (\n",
    "    pd.to_datetime(df_cosif_individual_full['DATA'].astype(str), format='%Y%m')\n",
    "      .dt.strftime('%Y%m')\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "df_cosif_individual = (\n",
    "    df_cosif_individual_full\n",
    "    .pivot_table(\n",
    "        index=['DATA', 'CNPJ', 'NOME_INSTITUICAO', 'TAXONOMIA'],\n",
    "        columns='CONTA',\n",
    "        values='SALDO'\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_cosif_individual.to_parquet(\n",
    "    dir_outputs / 'df_cosif_individual_wide.parquet',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "\n",
    "# 6.3. Merge Individual (wide) + Prudencial (mapping)\n",
    "df_cosif_full = df_cosif_individual.merge(\n",
    "    df_prud_mapping,\n",
    "    on=['DATA', 'CNPJ'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_cosif_full.to_parquet(\n",
    "    dir_outputs / 'df_cosif_full.parquet',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "\n",
    "# 6.4. Merge final com IFDATA (raw)\n",
    "# Certificar que df_if_combined já tem 'DATA' como inteiro\n",
    "if 'DATA' in df_if_combined.columns:\n",
    "    df_if_combined['DATA'] = pd.to_numeric(df_if_combined['DATA'], errors='coerce')\n",
    "\n",
    "df_final = df_cosif_full.merge(\n",
    "    df_if_combined,\n",
    "    on=['DATA', 'COD_CONGL'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_final.to_parquet(\n",
    "    dir_outputs / 'df_final.parquet',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "df_final.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell N+1: Preparar df_ind_pre a partir de df_cosif_individual_full =====\n",
    "\n",
    "# Partindo de df_cosif_individual_full (já tem 'DATA' formatado como int)\n",
    "df_ind_pre = (\n",
    "    df_cosif_individual_full\n",
    "    .assign(\n",
    "        CNPJ=lambda d: d['CNPJ'].astype(str).str.replace(r'[^0-9]', '', regex=True)\n",
    "    )\n",
    "    .drop(columns=['COD_CONGL', 'NOME_CONGL'], errors='ignore')\n",
    ")\n",
    "\n",
    "print(\"Colunas de df_ind_pre:\", df_ind_pre.columns.tolist())\n",
    "print(\"Shape de df_ind_pre:\", df_ind_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell N+2: Preparar df_prud_mapping a partir de df_cosif_prudencial_full =====\n",
    "\n",
    "# Partindo de df_cosif_prudencial_full (já tem 'DATA' formatado como int)\n",
    "df_pru_pre = (\n",
    "    df_cosif_prudencial_full\n",
    "    .assign(\n",
    "        CNPJ=lambda d: d['CNPJ'].astype(str).str.replace(r'[^0-9]', '', regex=True),\n",
    "        COD_CONGL=lambda d: d['COD_CONGL'].astype(str)\n",
    "    )\n",
    ")\n",
    "\n",
    "df_prud_mapping = (\n",
    "    df_pru_pre[['DATA', 'CNPJ', 'COD_CONGL', 'NOME_CONGL']]\n",
    "    .drop_duplicates(subset=['DATA', 'CNPJ'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Colunas de df_prud_mapping:\", df_prud_mapping.columns.tolist())\n",
    "print(\"Shape de df_prud_mapping:\", df_prud_mapping.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell N+3: Criar df_cosif_full_corrigido (merge Individual + Prudencial) =====\n",
    "\n",
    "df_cosif_full_corrigido = pd.merge(\n",
    "    df_ind_pre,\n",
    "    df_prud_mapping,\n",
    "    on=['DATA', 'CNPJ'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "print(\"Shape COSIF Full corrigido:\", df_cosif_full_corrigido.shape)\n",
    "print(\n",
    "    \"Linhas sem COD_CONGL (valores NaN em COD_CONGL):\",\n",
    "    df_cosif_full_corrigido['COD_CONGL'].isna().sum()\n",
    ")\n",
    "\n",
    "# Salvar parquet corrigido\n",
    "df_cosif_full_corrigido.to_parquet(\n",
    "    dir_outputs / 'df_cosif_full_corrigido.parquet',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4203c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell N+4: Preparar df_if_pre a partir de df_if_combined =====\n",
    "\n",
    "df_if_pre = (\n",
    "    df_if_combined\n",
    "    .assign(\n",
    "        DATA=lambda d: pd.to_numeric(d['DATA'], errors='coerce').astype(int),\n",
    "        COD_CONGL=lambda d: d['COD_CONGL'].astype(str)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Colunas de df_if_pre:\", df_if_pre.columns.tolist())\n",
    "print(\"Shape de df_if_pre:\", df_if_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell N+5: Criar df_final_corrigido (merge COSIF Full corrigido + IFDATA) =====\n",
    "\n",
    "df_final_corrigido = pd.merge(\n",
    "    df_cosif_full_corrigido.assign(COD_CONGL=lambda d: d['COD_CONGL'].astype(str)),\n",
    "    df_if_pre,\n",
    "    on=['DATA', 'COD_CONGL'],\n",
    "    how='left',\n",
    "    validate='many_to_many'\n",
    ")\n",
    "\n",
    "print(\"Shape DF Final corrigido:\", df_final_corrigido.shape)\n",
    "print(\n",
    "    \"Linhas sem informação de IFDATA (TipoInstituicao == NaN):\",\n",
    "    df_final_corrigido['TipoInstituicao'].isna().sum()\n",
    ")\n",
    "\n",
    "# Salvar parquet corrigido\n",
    "df_final_corrigido.to_parquet(\n",
    "    dir_outputs / 'df_final_corrigido.parquet',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell N+6 (opcional): Informações finais dos DataFrames corrigidos =====\n",
    "\n",
    "print(\"\\n=== Resumo Final ===\")\n",
    "print(\"df_cosif_full_corrigido:\")\n",
    "df_cosif_full_corrigido.info()\n",
    "\n",
    "print(\"\\ndf_final_corrigido:\")\n",
    "df_final_corrigido.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
